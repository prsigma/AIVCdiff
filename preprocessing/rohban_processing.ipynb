{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/datasets/cpg0017-rohban-pathways/2013_10_11_SIGMA2_Pilot/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read metadata file containing cell painting channel addresses for all replicates/experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over folders in root\n",
    "df = pd.DataFrame()\n",
    "for folder in os.listdir(root):\n",
    "    print(folder)\n",
    "    df_tmp = pd.read_csv(root + folder + \"/load_data_with_illum.csv\")\n",
    "    if df.empty:\n",
    "        df = df_tmp\n",
    "        print(df.columns)\n",
    "    else:\n",
    "        df = pd.concat([df, df_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique values of Metadata_Well column with counts of each value\n",
    "well_counts = df[\"Metadata_Well\"].value_counts()\n",
    "# print min, max, and mean of well counts\n",
    "print('Min: ', well_counts.min())\n",
    "print('Max: ', well_counts.max())\n",
    "print('Mean: ', well_counts.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read metadata file which contains well_position, gene_name, pert_name, broad_sample, cell_line, ASSAY_WELL_ROLE, and GeneID information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(\"/datasets/cpg0017-rohban-pathways/platemaps/2013_10_11_SIGMA2_Pilot/platemap/TAORF_REFERENCE_SET_2.txt\", sep=\"\\t\")\n",
    "# rename well_position column name with Metadata_Well\n",
    "metadata_df = metadata_df.rename(columns={\"well_position\": \"Metadata_Well\"})\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the dataframe containing channel addresses with the dataframe containing well info and gene names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df, metadata_df, on=\"Metadata_Well\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(root, experiment):\n",
    "    \"\"\"Create folders for resized and cropped images\n",
    "\n",
    "    Args:\n",
    "        root (str): root directory\n",
    "        experiment (str): experiment name\n",
    "    \"\"\"\n",
    "    folder_list = ['generated_imgs', 'ground_truth', 'train_imgs']\n",
    "    # create folder root+experiment+'_resized' and root+experiment+'_cropped' if they don't exist\n",
    "    experiment_path = [root+experiment+'_resized',\n",
    "                       root+experiment+'_cropped']\n",
    "    for path in experiment_path:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            for folder in folder_list:\n",
    "                if not os.path.exists(path + '/' + folder):\n",
    "                    os.makedirs(path + '/' + folder)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_illuminated_corrected_channel(row, channel, img_root, illum_root):\n",
    "    \"\"\" Responsible for loading the image and illumination correction file and correcting the pixel values.\n",
    "\n",
    "    Args:\n",
    "        row (pd.DataFrame): pd dataframe row\n",
    "        channel (str): name of channel\n",
    "        img_root (str): address of the image root\n",
    "        illum_root (str): address of the illumination correction root\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: illuminated corrected image\n",
    "    \"\"\"\n",
    "    channel_file = row[\"FileName_Orig\"+channel]\n",
    "    channel_path = row[\"PathName_Orig\"+channel]\n",
    "    batch = channel_path.split(\"/\")[-1]\n",
    "    channel_address = img_root + batch + \"/\" + channel_file\n",
    "    img = Image.open(channel_address)\n",
    "    img = np.asarray(img)\n",
    "    img = cv2.normalize(\n",
    "        img, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "            \n",
    "    # load illumination correction file\n",
    "    illum_file = row[\"FileName_Illum\"+channel]\n",
    "    illum_address = illum_root + batch + \"/\" + illum_file   \n",
    "    # read .npy file \n",
    "    illum = np.load(illum_address)\n",
    "\n",
    "    # apply illumination correction\n",
    "    img = img / illum\n",
    "    assert img.min() >= 0 and img.max() <= 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_resized_img(img, experiment, row):\n",
    "    \"\"\" Responsible for resizing the image and saving it in the appropriate folder.\n",
    "\n",
    "    Args:\n",
    "        img (torch.tensor): illumination corrected image\n",
    "        experiment (str): name of the experiment\n",
    "    \"\"\"\n",
    "    perturbation = row['gene_name'].lower()\n",
    "    # check if perturbation folder exists in the experiment dictionary and create it if it doesn't\n",
    "    if not os.path.exists(experiment + '_resized/ground_truth/' + perturbation):\n",
    "        os.makedirs(experiment + '_resized/ground_truth/' + perturbation)\n",
    "\n",
    "    if not os.path.exists(experiment + '_resized/train_imgs/train'):\n",
    "        os.makedirs(experiment + '_resized/train_imgs/train')\n",
    "\n",
    "    transform = transforms.Resize((512, 512))\n",
    "    img = img.permute(2, 0, 1)\n",
    "    img_resized = transform(img).numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    sample_name = '_'.join(row['FileName_OrigAGP'].split('_')[:3])+'_'+row['PathName_OrigAGP'].split('/')[-1]\n",
    "\n",
    "    files = os.listdir(experiment + '_resized/train_imgs/train/')\n",
    "    if sample_name+'.png' in files:\n",
    "        print('Image already exists')\n",
    "        print(sample_name+'.png')\n",
    "        return\n",
    "    \n",
    "    if img_resized.max() < 60:\n",
    "        print('Image is too dark')\n",
    "        return\n",
    "    cv2.imwrite(\n",
    "        experiment+'_resized/ground_truth/'+perturbation+'/'+sample_name+'.png', img_resized)\n",
    "    cv2.imwrite(\n",
    "        experiment+'_resized/train_imgs/train/'+sample_name+'.png', img_resized)\n",
    "    \n",
    "    line = {\n",
    "        \"file_name\": sample_name+'.png',\n",
    "        \"additional_feature\": perturbation\n",
    "    }\n",
    "    \n",
    "    if not os.path.exists(experiment + '_resized/train_imgs/train/metadata.jsonl'):\n",
    "        with open(experiment + '_resized/train_imgs/train/metadata.jsonl', 'w') as f:\n",
    "            f.write(json.dumps(line) + '\\n')\n",
    "    else:\n",
    "        with open(experiment + '_resized/train_imgs/train/metadata.jsonl', 'a') as f:\n",
    "            f.write(json.dumps(line) + '\\n')\n",
    "    # print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cropped_img(img, experiment, row):\n",
    "    \"\"\" Responsible for cropping the image and saving it in the appropriate folder.\n",
    "    \n",
    "    Args:\n",
    "        img (torch.tensor): illumination corrected image\n",
    "        experiment (str): name of the experiment\n",
    "        row (pd.DataFrame): pd dataframe row\n",
    "    \"\"\"\n",
    "    perturbation = row['gene_name'].lower()\n",
    "    # check if perturbation folder exists in the experiment dictionary and create it if it doesn't\n",
    "    if not os.path.exists(experiment + '_cropped/ground_truth/' + perturbation):\n",
    "        os.makedirs(experiment + '_cropped/ground_truth/' + perturbation)\n",
    "\n",
    "    if not os.path.exists(experiment + '_cropped/train_imgs/train'):\n",
    "        os.makedirs(experiment + '_cropped/train_imgs/train')\n",
    "        \n",
    "    sample_name = '_'.join(row['FileName_OrigAGP'].split('_')[:3])+'_'+row['PathName_OrigAGP'].split('/')[-1]\n",
    "    files = os.listdir(experiment+'_cropped/train_imgs/train/')\n",
    "    if sample_name+'.png' in files:\n",
    "        print('Image already exists')\n",
    "        print(sample_name+'.png')\n",
    "        return\n",
    "\n",
    "    # crop the image\n",
    "    transform = transforms.FiveCrop((512, 512))\n",
    "    img = img.permute(2, 0, 1)\n",
    "    cropped_imgs = transform(img)\n",
    "    for idx in range(len(cropped_imgs)):\n",
    "        img = cropped_imgs[idx].numpy().transpose(1, 2, 0)\n",
    "\n",
    "        if img.max() < 60:\n",
    "            continue\n",
    "        cv2.imwrite(\n",
    "            experiment+'_cropped/ground_truth/'+perturbation+'/'+sample_name+'_'+str(idx)+'.png', img)\n",
    "        cv2.imwrite(\n",
    "            experiment+'_cropped/train_imgs/train/'+sample_name+'_'+str(idx)+'.png', img)\n",
    "        \n",
    "        line = {\n",
    "            \"file_name\": sample_name+'_'+str(idx)+'.png',\n",
    "            \"additional_feature\": perturbation\n",
    "        }\n",
    "        \n",
    "        if not os.path.exists(experiment+'_cropped/train_imgs/train/metadata.jsonl'):\n",
    "            with open(experiment+'_cropped/train_imgs/train/metadata.jsonl', 'w') as f:\n",
    "                f.write(json.dumps(line) + '\\n')\n",
    "        else:\n",
    "            with open(experiment+'_cropped/train_imgs/train/metadata.jsonl', 'a') as f:\n",
    "                f.write(json.dumps(line) + '\\n')\n",
    "\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_illumination(df, channel_list, experiment):\n",
    "    \"\"\" Responsible for correcting the illumination of the images and saving them in the appropriate folders.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): pd dataframe\n",
    "        channel_list (list): list of channel names\n",
    "        experiment (str): name of the experiment\n",
    "    \"\"\"\n",
    "    \n",
    "    root = '/datasets/cpg0017-rohban-pathways/'\n",
    "    create_folder(root, experiment)\n",
    "    img_root = root + 'images/'\n",
    "    illum_root = root + 'illum/'\n",
    "\n",
    "    # loop over rows in df\n",
    "    for index, row in df.iterrows():\n",
    "        # loop over channels in channel_list\n",
    "        ch1 = get_illuminated_corrected_channel(\n",
    "            row, channel_list[0], img_root, illum_root)\n",
    "        ch2 = get_illuminated_corrected_channel(\n",
    "            row, channel_list[1], img_root, illum_root)\n",
    "        ch3 = get_illuminated_corrected_channel(\n",
    "            row, channel_list[2], img_root, illum_root)\n",
    "\n",
    "        merged_image = np.dstack((ch1, ch2, ch3))\n",
    "        img = torch.from_numpy(merged_image)\n",
    "\n",
    "        save_resized_img(img, root+experiment, row)\n",
    "        save_cropped_img(img, root+experiment, row)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment_directories(experiment, gene_list, channel_list):\n",
    "    \"\"\" Responsible for creating directories for the experiment and calling the correct_illumination function.\n",
    "    \n",
    "    Args:\n",
    "        experiment (str): name of the experiment\n",
    "        gene_list (list): list of gene names\n",
    "        channel_list (list): list of channel names\n",
    "    \"\"\"\n",
    "    # lowercase the gene names\n",
    "    df_merged[\"gene_name\"] = df_merged[\"gene_name\"].str.lower()\n",
    "    gene_list = [gene.lower() for gene in gene_list]\n",
    "\n",
    "    # extract rows with gene_list in the gene_name column\n",
    "    experiment_df = df_merged[df_merged[\"gene_name\"].isin(gene_list)]\n",
    "    experiment = experiment+'_'+'_'.join(channel_list)\n",
    "    print('Experiment name:', experiment)\n",
    "    print('Number of images for each gene in '+experiment+': ')\n",
    "    print(experiment_df[\"Metadata_Well\"].value_counts())\n",
    "    print(experiment_df[\"gene_name\"].value_counts())\n",
    "    print(experiment_df.shape)\n",
    "    correct_illumination(experiment_df, channel_list, experiment)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "def create_collage(experiment, channel_list, preprocessing):\n",
    "    \"\"\" Create a 10x10 collage of 100 randomly selected images from the training set.\n",
    "    \n",
    "    Args:\n",
    "        experiment (str): name of the experiment\n",
    "        channel_list (list): list of channels\n",
    "        preprocessing (str): preprocessing method\n",
    "    \"\"\"\n",
    "    directory = '/datasets/cpg0017-rohban-pathways/'+ \\\n",
    "        experiment+'_'+'_'.join(channel_list)+'_'+preprocessing+ \\\n",
    "        '/train_imgs/train/'\n",
    "    # Get all .png files in the directory\n",
    "    png_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.png')]\n",
    "    \n",
    "    # Randomly select 100 .png files\n",
    "    selected_files = random.sample(png_files, 100)\n",
    "\n",
    "    # Open all selected images\n",
    "    images = [Image.open(file) for file in selected_files]\n",
    "    \n",
    "    # Determine the size for each small image in the collage (assuming all images are the same size)\n",
    "    width, height = images[0].size\n",
    "\n",
    "    # Create a blank 10x10 collage\n",
    "    collage_width = width * 10\n",
    "    collage_height = height * 10\n",
    "    collage = Image.new('RGB', (collage_width, collage_height))\n",
    "\n",
    "    # Paste each image into the collage\n",
    "    for index, image in enumerate(images):\n",
    "        x = (index % 10) * width\n",
    "        y = (index // 10) * height\n",
    "        collage.paste(image, (x, y))\n",
    "\n",
    "    # Save the collage\n",
    "    collage.save('figure/10-by-10-imgs/'+\n",
    "                 experiment+'_'+'_'.join(channel_list)+'_'+preprocessing+'.png')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 01 - Included 5 genes from Rohban et al, reported to be involved in pathways shown to have distinct morphology from DMSO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 1\n",
    "experiment = 'experiment_01'\n",
    "gene_list = ['RAC1', 'KRAS', 'CDC42', 'RHOA', 'PAK1']\n",
    "channel_list1 = ['RNA', 'Mito', 'DNA']\n",
    "\n",
    "create_experiment_directories(experiment, gene_list, channel_list1)\n",
    "\n",
    "# create_collage(experiment, channel_list1, 'resized')\n",
    "# create_collage(experiment, channel_list1, 'cropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment - based on Rohban et al 1F supplementary material. Included gene clusters with at least three genes, p-value of first pathway less than 0.01, and at least half of the genes associated with the GO term in the cluster vs. all the clusters. Randomely excluded one gene from each cluster during training to test OOD prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 3\n",
    "experiment = 'experiment_03'\n",
    "gene_allele_list = ['XBP1', 'MAPK14', # GO:0050663 cytokine secretion\n",
    "                    'RAC1_T17N', 'AKT1_E17K', 'AKT3', 'AKT3_E17K', # GO:0031294 lymphocyte costimulation\n",
    "                    'RHOA_Q63L', 'PRKACA', # GO:0007043 cell-cell junction assembly\n",
    "                    'SMAD4', 'RPS6KB1', # GO:0001657 ureteric bud development\n",
    "                    'KRAS', 'BRAF', 'RAF1', # GO:0000186 activation of MAPKK activity\n",
    "                    ]\n",
    "gene_list = []\n",
    "for allele in gene_allele_list:\n",
    "    \n",
    "    # check if there is any row in df_merged with gene_name or pert_name equal to allele and save its gene_name\n",
    "    gene_name = df_merged[df_merged[\"gene_name\"] == allele][\"gene_name\"].values\n",
    "    allele_name = df_merged[df_merged[\"pert_name\"] == allele][\"gene_name\"].values\n",
    "    gene_list_tmp = list(gene_name) + list(allele_name)\n",
    "    gene_list += list(set(gene_list_tmp))\n",
    "    print('Allele: '+allele+' - Gene name: ', list(set(gene_list_tmp)))\n",
    "    \n",
    "channel_list1 = ['RNA', 'Mito', 'DNA']\n",
    "print('gene list:', gene_list)\n",
    "\n",
    "create_experiment_directories(experiment, gene_list, channel_list1)\n",
    "\n",
    "# create_collage(experiment, channel_list1, 'resized')\n",
    "# create_collage(experiment, channel_list1, 'cropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create experiment 04 including untreated cells labeled with EMPTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 4\n",
    "experiment = 'experiment_04'\n",
    "gene_list = ['EMPTY']\n",
    "channel_list1 = ['RNA', 'Mito', 'DNA']\n",
    "\n",
    "create_experiment_directories(experiment, gene_list, channel_list1)\n",
    "\n",
    "# create_collage(experiment, channel_list1, 'resized')\n",
    "# create_collage(experiment, channel_list1, 'cropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate gene embedding from scGPT, from: https://github.com/bowang-lab/scGPT/blob/main/tutorials/Tutorial_GRN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "import scgpt as scg\n",
    "from scgpt.tasks import GeneEmbedding\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.model import TransformerModel\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt.utils import set_seed \n",
    "\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "# n_hvg = 1200\n",
    "n_bins = 51\n",
    "mask_value = -1\n",
    "pad_value = -2\n",
    "n_input_bins = n_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model path; here we load the pre-trained scGPT model downloaded from the scGPT repository\n",
    "model_dir = Path(\"scgpt/scGPT_human\")\n",
    "model_config_file = model_dir / \"args.json\"\n",
    "model_file = model_dir / \"best_model.pt\"\n",
    "vocab_file = model_dir / \"vocab.json\"\n",
    "\n",
    "vocab = GeneVocab.from_file(vocab_file)\n",
    "for s in special_tokens:\n",
    "    if s not in vocab:\n",
    "        vocab.append_token(s)\n",
    "\n",
    "# Retrieve model parameters from config files\n",
    "with open(model_config_file, \"r\") as f:\n",
    "    model_configs = json.load(f)\n",
    "print(\n",
    "    f\"Resume model from {model_file}, the model args will override the \"\n",
    "    f\"config {model_config_file}.\"\n",
    ")\n",
    "embsize = model_configs[\"embsize\"]\n",
    "nhead = model_configs[\"nheads\"]\n",
    "d_hid = model_configs[\"d_hid\"]\n",
    "nlayers = model_configs[\"nlayers\"]\n",
    "n_layers_cls = model_configs[\"n_layers_cls\"]\n",
    "\n",
    "gene2idx = vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "model = TransformerModel(\n",
    "    ntokens,\n",
    "    embsize,\n",
    "    nhead,\n",
    "    d_hid,\n",
    "    nlayers,\n",
    "    vocab=vocab,\n",
    "    pad_value=pad_value,\n",
    "    n_input_bins=n_input_bins,\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_file, map_location=torch.device('cpu')))\n",
    "    print(f\"Loading all model params from {model_file}\")\n",
    "except:\n",
    "    # only load params that are in the model and match the size\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = torch.load(model_file, map_location=torch.device('cpu'))\n",
    "    pretrained_dict = {\n",
    "        k: v\n",
    "        for k, v in pretrained_dict.items()\n",
    "        if k in model_dict and v.shape == model_dict[k].shape\n",
    "    }\n",
    "    for k, v in pretrained_dict.items():\n",
    "        print(f\"Loading params {k} with shape {v.shape}\")\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data-independent gene embeddings from scGPT\n",
    "gene_ids = np.array([id for id in gene2idx.values()])\n",
    "gene_embeddings = model.encoder(torch.tensor(gene_ids, dtype=torch.long).to(device))\n",
    "gene_embeddings = gene_embeddings.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df['gene_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene2idx.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter on the intersection between the rohban et al genes and scGPT's 30+K foundation model vocab\n",
    "gene_embeddings_rohban = {gene: gene_embeddings[i] for i, gene in enumerate(gene2idx.keys()) if gene in metadata_df['gene_name'].unique()}\n",
    "print('Retrieved gene embeddings for {} genes.'.format(len(gene_embeddings_rohban)))\n",
    "print(type(gene_embeddings_rohban))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 01 genes\n",
    "gene_list = ['RAC1', 'KRAS', 'CDC42', 'RHOA', 'PAK1']\n",
    "\n",
    "# check if the gene embedding inside gene_list is generated by scGPT\n",
    "for gene in gene_list:\n",
    "    if gene in list(gene_embeddings_rohban.keys()):\n",
    "        continue\n",
    "    else:\n",
    "        print(gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def write_dict_to_csv(input_dict, filename):\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        for key, values in input_dict.items():\n",
    "            \n",
    "            row = key.lower()\n",
    "            for value in gene_embeddings_rohban[key]:\n",
    "                row = row+','+str(value)\n",
    "            file.write(row+'\\n')\n",
    "\n",
    "write_dict_to_csv(gene_embeddings_rohban, 'required_file/rohban_scgpt_gene_embedding_dict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_to_embedding = pd.read_csv('required_file/rohban_scgpt_gene_embedding_dict.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_to_embedding.columns = ['gene_name'] + [str(i) for i in range(512)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_to_embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
